{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00igNhksq_d6",
   "metadata": {
    "id": "00igNhksq_d6"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# If you are on Google Colab, this sets up everything needed.\n",
    "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
    "wget -O requirements.txt https://cs7150.baulab.info/2022-Fall/setup/hw1_requirements.txt\n",
    "pip install -r requirements.txt\n",
    "# If you are not on Google Colab, you can run these pip requirements on your own command-line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd8dbff",
   "metadata": {
    "id": "2dd8dbff"
   },
   "source": [
    "# Homework 1. Foundations, and How to Code in Pytorch\n",
    "\n",
    "## Learning Objective\n",
    "\n",
    "The goal of this homework is to get you familar with some of the foundational mathematical and programming tools used in deep learning, so we will review a little bit of calculus and linear algebra and introduce you to the pytorch API.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You may already be familiar with pytorch, and if so, great - dive in to answer the questions below.\n",
    "\n",
    "If you are new to pytorch, your first step is to get the necessary background.  **Read and work through the notebooks in the [David's tips on how to read pytorch](https://github.com/davidbau/how-to-read-pytorch) series**, which will give you an overview of GPU usage, Autograd, optimizer classes, torch Modules, and data loading.  (Don't hand in those notebooks; no points for working through those other notebooks, though they are highly recommended and will be helpful for learning to answer the questions in the current notebook.) Hand in this current notebook completed.\n",
    "\n",
    "## Readings\n",
    "\n",
    "The following readings are not necessary to do this notebook, but you may find them interesting if you want to develop your sense for the origins of some of the important ideas in deep networks.\n",
    "\n",
    "The practice of modeling a neural network as a computational object was pioneered in this classic paper by Warren McCulloch and Walter Pitts, and we will follow along with some of their constructions envisioning neural networks as graphs that can implement logic:\n",
    "\n",
    "<a href=\"https://papers.baulab.info/McCullochPitts-1943.pdf\">Warren S. McCulloch and Walter Pitts,\n",
    "<em>A Logical Calculus of the Ideas Immanent in Nervous Activity</em>, 1943.\n",
    "</a>\n",
    "\n",
    "Pytorch is pretty new, but its modular architecture has a long history, with roots in the torch project, which is itself based on the ideas in this paper:\n",
    "\n",
    "<a href=\"https://papers.baulab.info/Bottou-1990.pdf\">Léon Bottou and Patrick Gallinari,\n",
    "<em>A Framework for the Cooperation of Learning Algorithms</em>, 1990.\n",
    "</a>\n",
    "\n",
    "We will talk about the cross-entropy loss.  The use of cross-entropy loss for neural network training has its roots root in the late-1980s realization that often the units of measurement that should be used by neural networks are units of probability, not only because of its elegance, but also its excellent performance.\n",
    "\n",
    "<a href=\"https://papers.baulab.info/Solla-1988.pdf\">Sarah Solla, Esther Levin and Michael Fleisher,\n",
    "<em>Accelerated Learning in Layered Neural Networks</em>, 1988.\n",
    "</a>\n",
    "\n",
    "We will play with a state-of-the-art diffusion model that was released recently.  The whole pipeline is complex, and it will take the whole semester to learn how its parts work, but a user's view of the model is descibed well in a blog post here:\n",
    "\n",
    "<a href=\"https://huggingface.co/blog/stable_diffusion\">Suraj Patil, Pedro Cuenca, Nathan Lambert and Patrick von Platen,\n",
    "<em>Stable Diffusion with Diffusers</em>, 2022.\n",
    "</a>\n",
    "\n",
    "More papers about the diffusion model are listed in that exercise.\n",
    "\n",
    "\n",
    "## Academic Integrity, Citations, and Collaborations\n",
    "\n",
    "**In all your homework, you must explicitly cite any sources (people or any materials) you consult.**\n",
    "\n",
    "In our class homework assignments, you should think about the problems yourself first before consulting outside help.  And when you do seek out help, we strongly advise you to find a fellow classmate to talk with and work together rather than copying an answer from the internet.  You will all learn much more by thinking collaboratively and explaining ideas to one another.\n",
    "\n",
    "But if you are alone and stuck and you find some really useful insight on Stack Overflow or Github or a blog or some chat channel thread on Discord, it is not cheating to use and learn from that insight <em>if you cite your sources</em>.  Learning from the internet is acceptable as long as you **do not misrepresent somebody else's work as your own**.  Include citations in your writeup text or in comments in your code.\n",
    "\n",
    "In this first exercise you will Google for a nice solution to a real problem and **make a proper citation of your source for the solution**.  In this specific problem you will only get points if you look it up and cite the source.  In general, avoid Googling and peeking at answers for homework problems, but in this problem we ask you to do it explicitly, and you should continue this practice of citing all your sources and collaborators in the future.  Linked citations are a very cool, polite, honest and useful practice in real life. In classwork, citations are *required*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92255f8",
   "metadata": {
    "id": "c92255f8"
   },
   "source": [
    "## Exercise 1.1: calculus review and autograd derivatives\n",
    "\n",
    "The pytorch autograd framework is usually used to compute first derivatives, but it is perfectly capable of calculating higher order partial derivatives.  In this exercise we will try it out.\n",
    "\n",
    "In the code below, a function $p_0(x) =$ `polynomial(x)` $= x^4 - 2 x^3 + 3 x^2 - 4 x + 5$ is given, and it is applied to a batch of 100 values of $x$ in the range $[-2, 3]$ given as `x = torch.linspace(-2.0, 3.0, 100)`.  The batch of 100 values of $p_0(x)$ is stored as `y`, and the results are plotted.\n",
    "\n",
    "**Question 1.1.1**  **Fill in the formula below.**  Understand why we suggest using gradients of `y.sum()`.\n",
    "\n",
    "If $y_i = p_0(x_i)$ and $s = \\sum_i y_i$, then the gradient $\\nabla_x s$ is a vector that has components $\\partial s / \\partial x_i$, given by:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial s}{\\partial x_i} = \\boxed{\\text{TODO: put your answer here}}\n",
    "$$\n",
    "\n",
    "**Question 1.1.2**  Fill in the code below.  To create your ground truth solutions, apply calculus by hand (just use the Power Rule) to compute the derivative of the polynomial, and put the formula in as the definition of `p1(x)`.  Plot the reults.  Do the same for `p2`, `p3` and `p4` for successive derivatives.  To plot results correctly, the results should be a batch of the same size as the input; you might need to use `torch.ones_like(x)` or `x**0` or something similar to make this work in some cases.\n",
    "\n",
    "Then make pytorch autograd do the work.  Enable gradient computations on `x` by adding the `requires_grad` flag when it is created, and then  modify the line that defines `dy_dx` to uncomment the call to `torch.autograd.grad` and make it work.  Plot the results and make sure it looks the same as `p1`. Add more calls to `torch.autograd.grad` to compute the 2nd, 3rd, and 4th derivatives, and plot the results, and make sure they look right.  The 2nd derivative should come from applying `grad` to the 1st derivative, and so on.  Take a look at the advice about higher-order gradients from the [pytorch documentation for `torch.autograd.grad`](https://pytorch.org/docs/stable/generated/torch.autograd.grad.html#torch.autograd.grad) if you get stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803441d9",
   "metadata": {
    "id": "803441d9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def polynomial(x):\n",
    "    return x**4 - 2 * x**3 + 3 * x**2 - 4 * x + 5\n",
    "\n",
    "# MODIFY THE CODE BELOW TO DEFINE p1, p2, p3, p4 and d2y_x, d3y_x, and d4y_x\n",
    "\n",
    "def p1(x):\n",
    "    return torch.zeros_like(x) # TODO: fix me to be the derivative of polynomial(x)\n",
    "def p2(x):\n",
    "    return torch.zeros_like(x) # TODO: fix me to be the derivative of p1(x)\n",
    "def p3(x):\n",
    "    return torch.zeros_like(x) # TODO: fix me to be the derivative of p2(x)\n",
    "def p4(x):\n",
    "    return torch.zeros_like(x) # TODO: fix me to be the derivative of p3(x)\n",
    "\n",
    "x = torch.linspace(-2.0, 3.0, 100) # TODO: fix me by adding requires_grad\n",
    "y = polynomial(x)\n",
    "\n",
    "[dy_dx] = [torch.zeros_like(x)] # torch.autograd.grad(y.sum(), [x])  # TODO: fix me\n",
    "[d2y_dx] = [torch.zeros_like(x)] # TODO: fix me to be the 2st derivative of y.sum() w.r.t. to x\n",
    "[d3y_dx] = [torch.zeros_like(x)] # TODO: fix me to be the 3rd derivative of y.sum() w.r.t. to x\n",
    "[d4y_dx] = [torch.zeros_like(x)] # TODO: fix me to be the 4th of y.sum() w.r.t. to x\n",
    "\n",
    "# DO NOT CHANGE THE PLOTTING CODE OR TESTS BELOW\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(12,4), sharey=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    ax1.set_title('Power rule')\n",
    "    for i in range(0, 5):\n",
    "        ax1.plot(x, [polynomial, p1, p2, p3, p4][i](x), label=f'$p_{i}(x)$')\n",
    "    ax1.legend()\n",
    "    ax2.set_title('Autograd')\n",
    "    ax2.plot(x, y, label='$y$')\n",
    "    ax2.plot(x, dy_dx, label='$dy/dx$')\n",
    "    for i in [2, 3, 4]:\n",
    "        ax2.plot(x, [d2y_dx, d3y_dx, d4y_dx][i-2], label=f'$d^{i}y/dx$')\n",
    "    ax2.legend()\n",
    "\n",
    "assert(all((p1(x) - dy_dx).abs() < 1e-5))\n",
    "assert(all((p2(x) - d2y_dx).abs() < 1e-5))\n",
    "assert(all((p3(x) - d3y_dx).abs() < 1e-5))\n",
    "assert(all((p4(x) - d4y_dx).abs() < 1e-5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1cfbd0",
   "metadata": {
    "id": "0d1cfbd0"
   },
   "source": [
    "## Exercise 1.2: McCullough-Pitts Neural Networks\n",
    "\n",
    "The modern conception of artificial neural networks is essentially the same as the model originally devised by [McCullough and Pitts in their seminal 1943 paper](https://papers.baulab.info/McCullochPitts-1943.pdf).  In that work, they observed that a biological neuron could be seen as an object that adds up its inputs, possibly weighting some inputs differently from others, and then firing an output only once some threshold is reached.  This can be modeled as a weighted sum followed by a nonlinearity:\n",
    "\n",
    "<img src=\"https://cs7150.baulab.info/2022-Fall/hw1/mp-model.png\" width=\"800\">\n",
    "\n",
    "McCullough and Pitts reasoned about such neurons individually or in very small networks, and they asked: what is the computational power of such networks? Can they reproduce any logical computation? We will follow along with their exploration by constructing networks for the various logical operations that can be created with two binary inputs.\n",
    "\n",
    "We begin by creating a `torch.nn.Module` for the step-function nonlinearity.  We call it `Sign` because it is based on the `sign` function, returning `+1` for positive numbers and `-1` for negative numbers.   Like any torch `Module`, it will be a callable object.  We define the calling behavior in our `forward` method.   Notice that, as is typical in pytorch, our `Sign` module is designed to be able to operate on batches of data gathered in a `Tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e8ecda",
   "metadata": {
    "id": "f9e8ecda"
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "class Sign(torch.nn.Module):\n",
    "    '''\n",
    "    The Sign nonlinearity is a step function that returns +1 for all positive\n",
    "    numbers and -1 for all negative numbers.  Zero stays as zero.\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        return x.sign()\n",
    "\n",
    "demo = Sign()\n",
    "x = Tensor([-3.14, 1e-6, 0.0, -0.0])\n",
    "print('Sign of', x, 'is', demo(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc80be0",
   "metadata": {
    "id": "4bc80be0"
   },
   "source": [
    "Next we implement a slightly more elaborate `torch.nn.Module` for a McCullough-Pitts neuron.\n",
    "\n",
    "The `McCulloughPittsNeuron` torch Module object computes both the weighted sum (as a `torch.nn.Linear` operation called `summation`) and the `Sign` activation nonlinearity.  The `forward` method does both steps.\n",
    "\n",
    "The `McCulloughPittsNeuron` object can take any number of inputs; the number and names of the inputs and output are configured in the constructor, and the multiple named inputs are provided to the neuron as a dictionary contaiing `Tensor`s.  They are designed to be wired together in `torch.nn.Sequential` sequences.\n",
    "\n",
    "Read the code below to see how to configure a small network of `McCulloughPittsNeuron`s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deef3945",
   "metadata": {
    "id": "deef3945"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from baukit import PlotWidget, show\n",
    "\n",
    "class McCulloughPittsNeuron(torch.nn.Module):\n",
    "    '''\n",
    "    A McCullough-Pitts Neuron.  It computes a weighted sum of any number of inputs,\n",
    "    then it thresholds the output through a nonlinear activation step function.\n",
    "    It pulls named inputs from an input dictionary and puts output into the\n",
    "    dictionary.  That allows networks to be created by sequencing neurons and\n",
    "    connecting them by using dictionary names.\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        net = McCulloughPittsNeuron(\n",
    "                weight_a = 0.5,\n",
    "                weight_b = -0.3,\n",
    "                weight_c = 2.0,\n",
    "                bias     = 1.0)\n",
    "        print(net(dict(\n",
    "                a=Tensor([1.0]),\n",
    "                b=Tensor([-1.0]),\n",
    "                c=Tensor([-1.0])))['out'])\n",
    "\n",
    "    The above creates a single neuron with three inputs a, b, and c plus some bias.\n",
    "    It is invoked by providing a dictionary of all the inputs as tensors.\n",
    "\n",
    "        net = torch.nn.Sequential(\n",
    "            McCulloughPittsNeuron(weight_a=-1.0, weight_b=1.0, output_name='d'),\n",
    "            McCulloughPittsNeuron(weight_b=1.0, weight_d=1.0, bias=1.0),\n",
    "        )\n",
    "        print(net(dict(a=Tensor([1.0]), b=Tensor([-1.0])))['out'])\n",
    "\n",
    "    The above creates and runs a network of two neurons in this configuration:\n",
    "    ```\n",
    "             a -----> +----------+\n",
    "                      | Neuron 0 | ---> d --+\n",
    "             b ---+-> +----------+          +--> +----------+\n",
    "                  |                              | Neuron 1 | ---> out\n",
    "                  +----------------------------> +----------+\n",
    "    ```\n",
    "    As the sequence is run, the dictionary grows; after the first neuron is run,\n",
    "    the dictionary contains a, b, and d.  After the second neuron is run, the\n",
    "    final dictionary contains a, b, d, and out.\n",
    "    '''\n",
    "    def __init__(self, bias=0.0, activation=Sign, output_name='out', **kwargs):\n",
    "        '''\n",
    "        Construct a neuron by specifying any number of input weights in the arguments:\n",
    "\n",
    "            weight_a:    The weight for the 'a' input.\n",
    "                         Each `weight_x` in the constructor adds an input named 'x'.\n",
    "            bias:        The constant bias to add to the weighted sum.\n",
    "            output_name: The output name, defaults to 'out'.\n",
    "            activation:  The nonlinearity to use; defaults to the \"Sign\" step function.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        # We use the pytorch Linear module with a one-dimenaional output\n",
    "        self.summation = torch.nn.Linear(len(kwargs), 1)\n",
    "        self.activation = None if activation is None else activation()\n",
    "        self.output_name = output_name\n",
    "        self.input_names = []\n",
    "        with torch.no_grad():\n",
    "            self.summation.bias[...] = bias\n",
    "            for k, v in kwargs.items():\n",
    "                assert k.startswith('weight_'), f'Bad argument {k}'\n",
    "                self.summation.weight[0, len(self.input_names)] = v\n",
    "                self.input_names.append(k[7:])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        The inputs should be a dictionary containing the expected input keys.\n",
    "        The results are computed.  Then the return value will be a copy of the\n",
    "        input dictionary, with the additional output tensor added.\n",
    "        '''\n",
    "        state = inputs.copy()\n",
    "        assert self.output_name not in state, f'Multiple {self.output_name}\\'s conflict'\n",
    "        x = torch.stack([inputs[v] for v in self.input_names], dim=1)\n",
    "        x = self.summation(x)[:,0]\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        state[self.output_name] = x\n",
    "        return state\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f'input_names={self.input_names}, output_name=\\'{self.output_name}\\''\n",
    "\n",
    "def visualize_logic(nets, arg1='a', arg2='b'):\n",
    "    '''\n",
    "    Pass any number of McCullough-Pitts neurons or neural networks with two\n",
    "    inputs named 'a' and 'b', and it will visualize all of their logic, using\n",
    "    white squares to indicate +1, black squares to indicate -1, and orange\n",
    "    squares to indicate intermediate values.\n",
    "    '''\n",
    "    grid = torch.Tensor([[\n",
    "        [-1.0, 1.0],\n",
    "        [-1.0, 1.0],\n",
    "    ], [\n",
    "        [ 1.0, 1.0],\n",
    "        [-1.0,-1.0],\n",
    "    ]])\n",
    "    a, b = grid\n",
    "    def make_viz(n, case=()):\n",
    "        if isinstance(n, list):\n",
    "            return [make_viz(net, case + (str(i+1),)) for i, net in enumerate(n)]\n",
    "        def make_plot(fig):\n",
    "            with torch.no_grad():\n",
    "                out = n({arg1: a.view(-1), arg2: b.view(-1)})['out'].view(a.shape)\n",
    "            [ax] = fig.axes\n",
    "            ax.imshow(out, cmap='hot', extent=[-2,2,-2,2], vmin=-1, vmax=1)\n",
    "            ax.invert_yaxis()\n",
    "            ax.xaxis.tick_top()\n",
    "            ax.tick_params(length=0)\n",
    "            ax.set_xticks([-1, 1], [f'{arg1}=-1', f'{arg1}=1'])\n",
    "            ax.set_yticks([-1, 1], [f'{arg2}=-1', f'{arg2}=1'])\n",
    "        return [PlotWidget(make_plot, figsize=(1.1,1.1), dpi=100, bbox_inches='tight'),\n",
    "                show.style(margin='0 0 20px 45%', textAlign='right'), f'case {\" \".join(case)}']\n",
    "    show([show.WRAP, make_viz(nets)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1887b7f9",
   "metadata": {
    "id": "1887b7f9"
   },
   "source": [
    "Below is an example of a two small networks using the `McCulloughPittsNeuron`:  One single-neuron network, and one two-neuron network.  The behavior of the networks on $\\pm 1$ input for `a` and `b` is visualized, with white for $+1$ output and black for $-1$; orange indicates an indecisive $0$.\n",
    "\n",
    "The networks correspond to the code below:\n",
    "\n",
    "<img src=\"https://cs7150.baulab.info/2022-Fall/hw1/mp-examples.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94828b5",
   "metadata": {
    "id": "a94828b5"
   },
   "outputs": [],
   "source": [
    "visualize_logic([\n",
    "    # First network: just one neuron.\n",
    "    McCulloughPittsNeuron(weight_a=1.0, weight_b=0.5, bias=0.5),\n",
    "\n",
    "    # Second network: two neurons hooked together.\n",
    "    torch.nn.Sequential(\n",
    "        McCulloughPittsNeuron(weight_a=-1.0, weight_b=1.0, bias=0.0, output_name='d'),\n",
    "        McCulloughPittsNeuron(weight_b=0.5, weight_d=0.5, bias=1.0),\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff574af4",
   "metadata": {
    "id": "ff574af4"
   },
   "source": [
    "**Exercise 3.1** Use `McCulloughPittsNeuron`s to implement and visualize all the following cases.\n",
    "<img src=\"https://cs7150.baulab.info/2022-Fall/hw1/mp-target.png\">\n",
    "\n",
    "How many of the cases are able to be handled using a **single** neuron?  $\\boxed{\\text{TODO: fill me in}}$\n",
    "\n",
    "What are the names for the logical operations that require multiple neurons?  $\\boxed{\\text{TODO: fill me in}}$\n",
    "\n",
    "Put your code for implemeintting and visualizing each of the 4 neural networks (or single-neuron networks) below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b793e39a",
   "metadata": {
    "id": "b793e39a"
   },
   "outputs": [],
   "source": [
    "# Modify this to implement and vidualize the networks\n",
    "\n",
    "#visualize_logic([\n",
    "    # TODO: list your 14 networks here.\n",
    "#])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f1d218",
   "metadata": {
    "id": "c2f1d218"
   },
   "source": [
    "## Exercise 1.3: Softmax, KL, Cross-Entropy, and Squared Error\n",
    "\n",
    "In the 1980's, researchers like [Sarah Solla](https://papers.baulab.info/Solla-1988.pdf) and [John Hopfield](https://papers.baulab.info/also/Hopfield-1987.pdf) discovered that networks are very effective when trained to model *probabilities* instead of just discrete binary logic.  Even in the case where the output should make a choice between two alternatives, it is often best to have the network output its estimate of the *probability distribution* of the choice to be made, rather than just a 0 or a 1.\n",
    "\n",
    "So in modern deep learning, we will often pursue the goal of matching some true vector of discrete probabilities $y \\in \\mathbb{R}^{n}$ by computing some model-predicted vector of probabilities $p \\in \\mathbb{R}^{n}$ that is derived from some raw neural network output $z \\in \\mathbb{R}^{n}$, and then measuring its deviation from some true distribution $y$.\n",
    "\n",
    "This problem of generating a predicted probability distribution $p$ to match some observed truth $y$ is is so central and common in deep networks that you should make sure you are very familiar with the specific clever functions that everybody uses to do it, and why this approach works so well.\n",
    "\n",
    "The modeling of $p$ and the measurement of the distance to $y$ is almost always done in the same way: **softmax** and **cross-entropy**.\n",
    "\n",
    "Here is what a the softmax-cross-entropy computation looks like, when modeling a choice between two alternatives:\n",
    "\n",
    "<img src=\"https://cs7150.baulab.info/2022-Fall/hw1/softmax-loss.png\" width=600>\n",
    "\n",
    "On the left we have some numbers $z$ that are computed with the intention of modeling some choices in the real world.  On the right we have a categorical probablity distribution $y$ that is the true distribution of the choices actually observed in the world.  (In our figure we have just drawn two choices, but a big model could estimate a distribution over hundreds or thousands of choices.)  In the middle, we have two steps.  First, $p$ is the result of using the \"softmax\" function to convert the arbitrarily-scaled numbers $z_i$ to nicely-scaled numbers $p_i$ between 0 and 1 that could be interpreted as a categorical probablity distribution.  Then to summarize the difference between the calculated $p$ and the true $y$, some loss $L$ is computed, where $L$ is a single number that will be small if the vectors $p$ and $y$ are close.  When working with categorical probabilities, $L$ is almost always the cross-entropy loss function, but other choices could be used.\n",
    "\n",
    "Below we introduce both the softmax and the cross-entropy (CE) loss function, and we also compare it to Kullback–Leibler (KL) divergence, as well as squared Euclidean vector distance, which is also known as the squared-error (SE) loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133f240d",
   "metadata": {
    "id": "133f240d"
   },
   "source": [
    "**Question 1.2.1**. Jacobians and the the softmax function.\n",
    "\n",
    "The [**softmax** function](https://en.wikipedia.org/wiki/Softmax_function) $p = \\text{softmax}(z) : \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{n}$ is defined as:\n",
    "\n",
    "$$\\text{softmax}(z)_i = p_i = \\frac{e^{z_{i}}}{\\sum_{j} e^{z_j}}$$\n",
    "\n",
    "It is used to convert an vector of arbitrary score numbers $z$ called *logits* into a vector $p$ that is a valid categorical probability distribution.  Fill in the following:\n",
    "\n",
    "Write the simplest expression for the sum of $\\text{softmax}(z)_i$ over all $i$:\n",
    "\n",
    "$$\\sum_i p_i = \\sum_i \\frac{e^{z_{i}}}{\\sum_{j} e^{z_j}} = \\boxed{\\text{TODO: fill me in}}$$\n",
    "\n",
    "The input to softmax $z$ are called *logits* because they can be through of as expressing probabilities on a logistic or log scale.  Now suppose we have some new logits $z^*$ which form a vector that is shifted from $z$ by $k$ in all dimensions, where $z^*_i = z_i + k$.  How does such a shift affect the softmax?  Work it out:\n",
    "\n",
    "Assuming we have $p = \\text{softmax}(z)$, write the simplest expression for $p^* = \\text{softmax}(z^*) = \\text{softmax}(z + k)$ in terms of only the original $p_i$ and $k$:\n",
    "\n",
    "$$p^*_{i} = \\boxed{\\text{TODO: fill me in}}$$\n",
    "\n",
    "This remarkable property means that the output of softmax does not depend so much on the specific values of $z_i$, but on the differences between the $z_i$.\n",
    "\n",
    "It is useful to know the derivatives of softmax. Remember that the [Jacobian of a vector function](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant) $f(z): \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{m}$ is the matrix\n",
    "\n",
    "$$\\mathbf{J}_{f}(z) = \\left[\\begin{matrix}\n",
    "\\frac{\\partial f_1}{\\partial z_1} &\n",
    "\\frac{\\partial f_1}{\\partial z_2} &\n",
    "... &\n",
    "\\frac{\\partial f_1}{\\partial z_n} \\\\\n",
    "\\frac{\\partial f_2}{\\partial z_1} &\n",
    "\\frac{\\partial f_2}{\\partial z_2} &\n",
    "... &\n",
    "\\frac{\\partial f_2}{\\partial z_n} \\\\\n",
    "\\vdots & & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f_m}{\\partial z_1} &\n",
    "\\frac{\\partial f_m}{\\partial z_2} &\n",
    "... &\n",
    "\\frac{\\partial f_m}{\\partial z_n}\n",
    "\\end{matrix}\\right]$$\n",
    "\n",
    "\n",
    "Work out the Jacobian for softmax in the case where $n=2$, writing the solutions for each partial derivative $\\frac{\\partial p_i}{\\partial z_j}$.  Write each partial derivative it in the simplest form in terms of $p_i$ (and try to eliminate $z_i$).  It might be helpful to combine terms by using the fact that $p_1 + p_2$ is a constant.  Try to work it out yourself even though this problem is solved all over the web.  Remember to cite your sources if you get help on the internet or with an AI.\n",
    "\n",
    "\n",
    "$$\\mathbf{J}_{\\text{softmax}}(z) =\n",
    "\\mathbf{J}_{p}(z) =\n",
    "\\left[\\begin{matrix}\n",
    "\\frac{\\partial p_1}{\\partial z_1} &\n",
    "\\frac{\\partial p_1}{\\partial z_2} \\\\\n",
    "\\frac{\\partial p_2}{\\partial z_1} &\n",
    "\\frac{\\partial p_2}{\\partial z_2}\n",
    "\\end{matrix}\\right] =\n",
    "\\left[\\begin{matrix}\n",
    "\\boxed{\\text{TODO: fill me in}} &\n",
    "\\boxed{\\text{TODO: fill me in}} \\\\\n",
    "\\boxed{\\text{TODO: fill me in}} &\n",
    "\\boxed{\\text{TODO: fill me in}}\n",
    "\\end{matrix}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd103d",
   "metadata": {
    "id": "92bd103d"
   },
   "source": [
    "**Question 1.2.2**. KL divergence, Cross-entropy, and mean squared error loss.\n",
    "\n",
    "To measure and optimize the goal of matching $p$ to some true real-world distribution $y$, we will need to define some number that summarizes the difference beween $y$ and $p$.  There are several natural possibilities to quantify the difference.  Since both $y$ and $p$ are $n$-dimensional vectors, one natural choice is to look at the squared [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance) between the two vectors; this is known as the [**squared error** loss](https://en.wikipedia.org/wiki/Mean_squared_error):\n",
    "\n",
    "$$\\text{SE}(y, p) = || y - p ||^2 =  \\sum_{i}  (y_i - p_i)^2$$\n",
    "\n",
    "What is the value of SE if $y = p$?\n",
    "\n",
    "$$\\text{SE}(y, y) = \\boxed{\\text{TODO: fill me in}}$$\n",
    "\n",
    "What is the partial derivative of $\\text{SE}(y, p)$ with respect to the $i$th component $p_i$?  It should be possible to express the answer in terms of just $y_i$ and $p_i$.\n",
    "\n",
    "$$\\frac{\\partial \\, \\text{SE}(y, p)}{\\partial p_i} = \\boxed{\\text{TODO: fill me in}}$$\n",
    "\n",
    "A different choice for comparing $y$ and $p$ is the famous **KL divergence** ([Wikipedia article here](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)) which is defined as\n",
    "\n",
    "$$\\text{KL}(y; p) = \\sum_i y_i \\log\\frac{y_i}{p_i}$$\n",
    "\n",
    "What is the value of KL divergence if $y = p$?\n",
    "\n",
    "$$\\text{KL}(y; y) = \\boxed{\\text{TODO: fill me in}}$$\n",
    "\n",
    "KL divergence can be written as the difference between entropy $\\text{H}(y)= -\\sum_i y_i \\log y_i$ and *cross-entropy* $\\text{CE}(y; p) = - \\sum_i y_i \\log p_i$ as follows:\n",
    "\n",
    "$$\\text{KL}(y; p) = \\sum_i y_i \\log y_i - \\sum_i y_i \\log p_i = \\text{CE}(y; p) - \\text{H}(y)$$\n",
    "$$\\text{CE}(y; p) = - \\sum_i y_i \\log p_i$$\n",
    "\n",
    "Since $H(y)$ is a constant that does not depend on the model outputs $p$, the shape of the cross-entropy loss is the same as the KL loss, just shifted by a constant.  In particular, when looking at derivatives of negative CE with respect to components of $p$, they are the same as derivatives of KL with respect to components of $p$.  Let us compute some of those derivatives.\n",
    "\n",
    "What is the partial derivative of $\\text{CE}(y; p)$ with respect to the $i$th component $p_i$?  It should be possible to express the answer in terms of just $y_i$ and $p_i$.\n",
    "\n",
    "$$\\frac{\\partial \\, \\text{CE}(y; p)}{\\partial p_i} = \\boxed{\\text{TODO: fill me in}}$$\n",
    "\n",
    "Convince yourself that this is the same as $\\frac{\\partial \\, \\text{KL}(y; p)}{\\partial p_i}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929136a2",
   "metadata": {
    "id": "929136a2"
   },
   "source": [
    "Let's go further back from $p_i$ and understand partial derivatives with respect to $z_i$.  Remember how the [chain rule works over vector functions](https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/differentiating-vector-valued-functions/a/multivariable-chain-rule-simple-version): for example if we wish to compute $\\partial L / \\partial z_1$, we must consider multiple paths, both the path through $p_1$ and the path through $p_2$.\n",
    "\n",
    "<img src=\"https://cs7150.baulab.info/2022-Fall/hw1/two-partial-paths.png\" width=\"320\">\n",
    "\n",
    "**Question 1.2.3**. Gradient of negative CE (or KL) loss on softmax, and gradient of SE loss on softmax.\n",
    "\n",
    "Using the chain rule to combine answers for 2.3 and 2.4, compute the following partial derivative of cross-entropy with respect to the first component $z_1$.  You should work to find simple expressions in terms of $p_1$ and $y_1$ instead of making a messy expression with the $z_i$.  To simplify terms, you may find it useful to remember thet $y_1 + y_2 = 1$ and $p_1 + p_2 = 1$.\n",
    "\n",
    "$$\\frac{\\partial \\, \\text{CE}(y; p)}{\\partial z_1} = \\boxed{\\text{TODO: fill me in}}$$\n",
    "\n",
    "Try to work it out on your own.  If you consult the internet, please add a citation.\n",
    "\n",
    "Next, compute the analogous partial derivative of SE with repect to $z_1$.  Again, keep the expression as simple as you can, using only $y_1$ and $p_1$ if you can.  Hint: it is a polynomial that can be written as the product of three terms.\n",
    "\n",
    "$$\\frac{\\partial \\, \\text{SE}(y, p)}{\\partial z_1} = \\boxed{\\text{TODO: fill me in}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0fe3d7",
   "metadata": {
    "id": "ce0fe3d7"
   },
   "source": [
    "Negative CE and SE applied to softmax have a lot of similarities, but they have some significant differences in their derivatives.\n",
    "\n",
    "Let us visualize these derivatives.\n",
    "\n",
    "Read and run the code below and interact with the widget.  It shows how the KL, CE, and SE loss vary as a function of the logits.  If you click on the CE checkbox, you can see how negative cross entropy is parallel to the KL loss curve.\n",
    "\n",
    "\n",
    "Also notice how SE is very different from KL. In particular, notice how SE loss suffers from **vanishing graidents**: it saturates in regions where the predicted answer $p$ is far from the true answer $y$.  The flatness of the SE loss means that it does not really distinguish between the quality of bad answers, and it can be hard to use SE as a guide to improve a bad answer.\n",
    "\n",
    "Also, notice that when the target probability $y$ is imbalanced, e.g., $y=0.1$, then SE is also noticably flatter than KL at the point of minimum loss, with a much flatter curvature.  That means that SE is very accepting of not-very-good answers whereas KL does a better job at distinguishing very-good answers from slightly less-good answers.\n",
    "\n",
    "**Question 1.2.4**. Plot and compare the partial derivatives of KL, and SE on softmax as well.\n",
    "\n",
    "In the code below, the plot on the right is incomplete because it does not include the correct plot of partial dervatives for KL and SE losses.  Copy your answers from 3.3 into the proper lines of the code below to visualize the derivatives as well.\n",
    "\n",
    "Notice that CE has exactly the same shape as KL.\n",
    "\n",
    "The plots you make explain why cross-entropy loss typically works much better than SE in practice.  While both KL and SE are flat at the optimal point, unlike KL, SE flattens out again when the logits are far from the optimal point.  We say that SE *saturates* and suffers from a *vanishing gradient* when the system is far from the optimum.  Optimizations behave like a rolling stone: if you were to put a stone on the SE loss curve, it could easily get stuck in the high flat area of the curve.  Whereas if you put a stone on the the KL loss curve, it would be on a steeper slope and roll quickly to the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab138f2e",
   "metadata": {
    "id": "ab138f2e"
   },
   "outputs": [],
   "source": [
    "from baukit import PlotWidget, Range, Checkbox, show\n",
    "import math\n",
    "\n",
    "xmin, xmax = -6.0, 6.0\n",
    "z = torch.stack([\n",
    "    torch.zeros(201),\n",
    "    torch.linspace(xmin, xmax, 201),\n",
    "])\n",
    "p = torch.softmax(z, dim=0)\n",
    "\n",
    "def compare_loss(fig, y1=0.5, dokl=True, dose=True, doce=True, dol1=True):\n",
    "    [ax1] = fig.axes\n",
    "    y0 = 1.0 - y1\n",
    "    kl = y0 * (math.log(y0) - torch.log(p[0])) + y1 * (math.log(y1) - torch.log(p[1]))\n",
    "    ce = y0 * ( - torch.log(p[0])) + y1 * ( - torch.log(p[1]))\n",
    "    se = ((p - torch.tensor([y0, y1])[:, None])**2).sum(0)\n",
    "    # sampled_se = (y0 * ((1-p[0])**2 + p[1]**2)) + (y1 * ((1-p[1])**2 + p[0]**2))\n",
    "    sampled_l1 = (2*y0*p[1] + 2*y1*p[0])\n",
    "    ax1.clear()\n",
    "    ax1.set_ylim(0, 3.0)\n",
    "    ax1.set_xlim(xmin, xmax)\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Difference between logits $z_1 - z_0$')\n",
    "    ax1.set_title(f'Loss curve on softmax when target $y_1={y1:.3f}$')\n",
    "\n",
    "    if dokl: ax1.plot(z[1], kl, label='KL', color='b')\n",
    "    if dose: ax1.plot(z[1], se, label='SE', color='r')\n",
    "    if doce: ax1.plot(z[1], ce, label='CE', color='g', linestyle='dashed', alpha=0.6)\n",
    "    if dol1: ax1.plot(z[1], sampled_l1, label='L1', color='orange', linestyle='dotted', alpha=0.7)\n",
    "    if dokl or dose or doce or dol1: ax1.legend()\n",
    "\n",
    "def compare_grad(fig, y1=0.5, dokl=True, dose=True):\n",
    "    [ax1] = fig.axes\n",
    "    y0 = 1.0 - y1\n",
    "    # TODO: fill me in so that d kl / d z1 is plotted.\n",
    "    dkl_dz1 = torch.zeros_like(z[1])\n",
    "    # TODO: fill me in so that d se / d z1 is plotted\n",
    "    dse_dz1 = torch.zeros_like(z[1])\n",
    "    ax1.clear()\n",
    "    ax1.set_ylim(-0.7, 0.7)\n",
    "    ax1.set_xlim(xmin, xmax)\n",
    "    ax1.set_xlabel('Difference between logits $z_1 - z_0$')\n",
    "    ax1.set_title(f'Gradient of loss with repect to $z_1$ when $y_1={y1:.3f}$')\n",
    "\n",
    "    if dokl:\n",
    "        ax1.plot(z[1], dkl_dz1, color='b', label=r'$\\frac{\\partial \\mathrm{KL}}{\\partial z_1}$' +\n",
    "            r'=$\\frac{\\partial \\mathrm{CE}}{\\partial z_1}$')\n",
    "    if dose:\n",
    "        ax1.plot(z[1], dse_dz1, color='r', label=r'$\\frac{\\partial \\mathrm{SE}}{\\partial z_1}$')\n",
    "    ax1.axhline(0, color='gray', linewidth=0.5)\n",
    "    if dokl or dose:\n",
    "        ax1.legend(loc='upper left')\n",
    "\n",
    "rw = Range(min=0.001, max=0.999, step=0.001, value=0.5)\n",
    "bkl = Checkbox('KL', value=True)\n",
    "bce = Checkbox('CE', value=False)\n",
    "bse = Checkbox('SE', value=True)\n",
    "bl1 = Checkbox('L1', value=False)\n",
    "ploss = PlotWidget(compare_loss, y1=rw.prop('value'),\n",
    "                   dokl=bkl.prop('value'), dose=bse.prop('value'),\n",
    "                   doce=bce.prop('value'), dol1=bl1.prop('value'),\n",
    "                   bbox_inches='tight')\n",
    "pgrad = PlotWidget(compare_grad, y1=rw.prop('value'),\n",
    "                   dokl=bkl.prop('value'), dose=bse.prop('value'),\n",
    "                   bbox_inches='tight')\n",
    "show([[show.raw_html('<div>target y<sub>1</sub> = </div>'),\n",
    "                       show.style(flex=12), rw,\n",
    "                       'Include:', bkl, bce, bl1, bse],\n",
    "                      [ploss, pgrad]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b662318",
   "metadata": {
    "id": "0b662318"
   },
   "source": [
    "## Exercise 1.3: loading and using a pretrained SOTA model\n",
    "\n",
    "Pytorch `Modules` make it easy to save, load, train, and use functions that are parameterized by lots of learned numbers.  In this exercise you will load a big state-of-the art deep network model and use it.  Do **not** worry that you do not understand how the specific model works or how it was trained.  We will be covering the concepts in the course, and if you would like to spend the semester understanding a specific state-of-the-art system like this, you can choose it for your final project.\n",
    "\n",
    "To see how this would work in the real world, we will use [Hugging Face](https://huggingface.co/), which a platform being developed by an AI startup to host pretrained models.\n",
    "\n",
    "**First, sign up** for a free huggingface.co account at https://huggingface.co/join if you don't already have one.\n",
    "\n",
    "**Second, log in.** After you have signed up, you need to set up a login authentication key with your notebook by running the following notebook cell.  This will allow your code to download some models through your account.  When it prompts you to go to https://huggingface.co/settings/tokens it is enough to create a \"Read\" token for this homework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885fbf74",
   "metadata": {
    "id": "885fbf74"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892efe90",
   "metadata": {
    "id": "892efe90"
   },
   "source": [
    "**Third, download the Stable Diffusion model pipeline** by running the following cell.  Stable Diffusion is very new, and these models were released on August 22, 2022.  Read this blog entry about it: https://huggingface.co/blog/stable_diffusion\n",
    "\n",
    "You do **not** need to understand the following citations.  The code we are downloading is by [Suraj Patil and others at Huggingface](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py), and it implements text-conditioned diffusion modeling to a VAE latent space, as devised by [Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer, \"High-Resolution Image Synthesis with Latent Diffusion Models\" (Latent Diffusion, CVPR 2022, https://arxiv.org/abs/2112.10752)](https://arxiv.org/abs/2112.10752) and trained by [stability.ai](https://stability.ai/blog/stable-diffusion-announcement).  The method directly builds on work by [Ho, et al (Denoising Diffusion, 2020)](https://papers.baulab.info/Ho-2020.pdf), [Radford, et al. CLIP 2021](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf), [Ho and Salimans (Classifier-free guidance, 2022)](https://arxiv.org/abs/2207.12598), [Ramesh, et al (Dall-E 2, 2022)](https://cdn.openai.com/papers/dall-e-2.pdf), [Saharia, et al (Imagen, 2022)](https://imagen.research.google/paper.pdf), and [Crowson (PLMS k-diffusion, 2022)](https://github.com/crowsonkb/k-diffusion).\n",
    "\n",
    "If the pipeline seems complex, be aware that the ideas did not all come from one person.\n",
    "\n",
    "The following cell will take a few minutes to download the models.  Running on a GPU machine is highly recommended.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067e330",
   "metadata": {
    "id": "5067e330"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# This function loads several neural networks to use together.\n",
    "# The individual networks and preprocessors loaded are listed in this file:\n",
    "# https://huggingface.co/CompVis/stable-diffusion-v1-4/blob/main/model_index.json\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\",\n",
    "    revision=\"fp16\",\n",
    "    torch_dtype=torch.float16,\n",
    "    use_auth_token=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc034a7",
   "metadata": {
    "id": "2dc034a7"
   },
   "source": [
    "**Question 1.3.1**.\n",
    "\n",
    "The following cell lists the objects contained in the loaded pipeline; some of these objects are neural networks and some are not.  Modify the cell below to figure out which of the four objects are neural networks (i.e., they extend `torch.nn.Module`) and then use `Module` methods to count how many submodules each one contains, how many Tensor parameters, and within those parameters, how many scalar parameters are within each network.\n",
    "\n",
    "Write the code to figure it out and include it in the following cell.\n",
    "\n",
    "Also, in answers into the following table.  One row is already given.\n",
    "\n",
    "| Attribute             | Type                         | Modules | Tensor params | Scalar params |\n",
    "| :-------------------- | :--------------------------- | ------- | --------------| ------------- |\n",
    "| TODO                  |               ?              |    ?    |       ?       |        ?      |\n",
    "| TODO                  |               ?              |    ?    |       ?       |        ?      |\n",
    "| TODO                  |               ?              |    ?    |       ?       |        ?      |\n",
    "| `pipe.safety_checker` | StableDiffusionSafetyChecker |   276   |      394      |   303,981,568 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e60771",
   "metadata": {
    "id": "27e60771"
   },
   "outputs": [],
   "source": [
    "for name, obj in vars(pipe).items():\n",
    "    print(f'pipe.{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be03a276",
   "metadata": {
    "id": "be03a276"
   },
   "source": [
    "Now run the code below.  You will likely need a GPU-enabled machine to run it.\n",
    "\n",
    "You **do not** need to understand every line, but if you are curious what is going on, [this blog entry about the stable diffusion code](https://huggingface.co/blog/stable_diffusion) is informative.\n",
    "\n",
    "Try it with your own prompts.  Can you come up with any interesting insights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2012ed",
   "metadata": {
    "id": "fc2012ed"
   },
   "outputs": [],
   "source": [
    "from baukit import show, renormalize, pbar\n",
    "from torch import autocast\n",
    "import numpy\n",
    "\n",
    "prompt = \"Photo of Chewbacca and Angela Merkel solving a Rubik's cube on Boston Common\"\n",
    "seed = 1\n",
    "\n",
    "# Stable Diffusion inference devised by Robin Rombach et al. (CVPR 2022, https://arxiv.org/abs/2112.10752)\n",
    "# Derived from the Huggingface Stable Diffusion pipeline by Suraj Patil and others\n",
    "# https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L16-L171\n",
    "with autocast(device), torch.no_grad():\n",
    "    text_tokens = pipe.tokenizer([\"\", prompt], padding=\"max_length\", return_tensors=\"pt\")['input_ids']\n",
    "    text_vectors = pipe.text_encoder(text_tokens.to(device))[0]\n",
    "    image_vectors = torch.from_numpy(numpy.random.RandomState(seed).randn(1, 4, 64, 64)).float().to(device)\n",
    "\n",
    "    # The scheduler uses a linear multistep (PLMS) method proposed by Katherine Crowson\n",
    "    # https://github.com/crowsonkb/k-diffusion\n",
    "    scheduler = pipe.scheduler\n",
    "    scheduler.set_timesteps(33)\n",
    "    latent_scale = 0.18215\n",
    "    guidance_strength = 5.0\n",
    "    intermediates = []\n",
    "    for i, t in enumerate(pbar(scheduler.timesteps)):\n",
    "        if i % 6 == 0:\n",
    "            intermediates.extend(renormalize.as_image(pipe.vae.decode(image_vectors / latent_scale).sample))\n",
    "        # Pass two copies into the network, one to process with \"\" and the other with prompt.\n",
    "        image_vector_input = torch.cat([image_vectors] * 2)\n",
    "        # pipe.unet is a neural network inputs image_vector_inputs and text_vectors and outputs some updates\n",
    "        update = pipe.unet(image_vector_input, t, text_vectors)[\"sample\"]\n",
    "        # Classifier-free guidance: see Jonathan Ho and Tim Salimans\n",
    "        # (Neurips 2021 Workshop, https://arxiv.org/abs/2207.12598)\n",
    "        strong_guidance = update[0] + guidance_strength * (update[1] - update[0])\n",
    "        image_vectors = scheduler.step(strong_guidance, t, image_vectors)[\"prev_sample\"]\n",
    "\n",
    "    # pipe.vae is a neural network\n",
    "    rgb_vectors = pipe.vae.decode(image_vectors / latent_scale).sample\n",
    "    intermediates.extend(renormalize.as_image(rgb_vectors))\n",
    "    show(show.WRAP, [[show.style(width=144), im] for im in intermediates])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5a2082",
   "metadata": {
    "id": "1e5a2082"
   },
   "source": [
    "**Question 1.3.2**.\n",
    "\n",
    "Data flows through the pipeline in four tensors: `text_tokens`, `text_vectors`, `image_vectors`, and `rgb_vectors`.\n",
    "\n",
    "Write some code below to check the `shape` and `dtype` for each of these tensors, and then determine the role of each of the tensor dimensions.  Then fill in the following table.\n",
    "\n",
    "**Enter your answers into this table**\n",
    "\n",
    "| Tensor           | Dtype      |       Shape |   numel | batch size | feature size, if any | spatial size, if any |\n",
    "| :--------------- | :--------- | ----------- | --------| ---------- | -------------------- | -------------------- |\n",
    "| `text_tokens`    | ?          |           ? |       ? |          ? |                    ? |                    ? |\n",
    "| `text_vectors`   | ?          |           ? |       ? |          ? |                    ? |                    ? |\n",
    "| `image_vectors`  | ?          |           ? |       ? |          ? |                    ? |                    ? |\n",
    "| `rgb_vectors`    | float16    | 1x3x512x512 | 786,432 |          1 |              3 (RGB) |    512 (y) x 512 (x) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c7c891",
   "metadata": {
    "id": "07c7c891"
   },
   "outputs": [],
   "source": [
    "# Use this cell to write test code to check the size, type, and meaning of each tensor dimension\n",
    "pipe.tokenizer.decode(text_tokens[1,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce03ea5e",
   "metadata": {
    "id": "ce03ea5e"
   },
   "source": [
    "## Exercise 1.4: use a dataloader and run a NSFW filter\n",
    "\n",
    "The Stable Diffusion pipeline comes with a NSFW filter neural network called `safety_checker`.\n",
    "\n",
    "In this exercise, you will test out this network by passing 1000 images to it.\n",
    "\n",
    "Like most pytorch neural networks, this network is configured to run on *batches* of data.  You will pass the images to the network in batches of 10, using a DataLoader with `batch_size=10`.\n",
    "\n",
    "The code below downloads a small classroom dataset called `coco_humans` of *individual* images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c1ded7",
   "metadata": {
    "id": "68c1ded7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.datasets.utils import download_and_extract_archive\n",
    "\n",
    "if not os.path.isdir('coco_humans'):\n",
    "    download_and_extract_archive('https://cs7150.baulab.info/2023-Fall/data/coco_humans.zip', 'coco_humans')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff3daad",
   "metadata": {
    "id": "dff3daad"
   },
   "source": [
    "Here is some information about the `safety_checker` neural network.\n",
    "\n",
    "In pytorch, a neural network is a `torch.nn.Module`, and every `torch.nn.Module` is a *callable* object that can be called just like a function.\n",
    "\n",
    "To see how to call `pipe.safetey_checker` you can consult the original Stable Diffusion code that calls it:  https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L166\n",
    "\n",
    "```image, has_nsfw_concept = self.safety_checker(images=image, clip_input=safety_cheker_input.pixel_values)```\n",
    "\n",
    "\n",
    "Specifically, the `safety_checker` network is expecting two inputs when it is called.\n",
    "\n",
    "The second `clip_input` argument is quite typical and conventional for a vision network.  It is a read-only 4-dimensional pytorch tensor that should contain the number data for a batch of normalized RGB images that the network will examine for possible offensive images.\n",
    "\n",
    "To pass a batch of 10 images as `clip_input`, you will need to normalize the data correctly - that is, you will need to paticular minimum and maximum numbers to represent the range from black pixels to white pixels, and you will want to use the same range that the network expects.  Since this is a \"CLIP\" network, it expects CLIP standard normalization as defined in the `clip_transform` in the code below (source is cited in the code).  Check the `torchvision.datasets.ImageFolder` documentation about how to use an image transform like this when loading data.\n",
    "\n",
    "The first `safety_checker` argument, `images`, is pretty unusual for a neural network, and we can almost ignore it.  It is a mutable list of tensors for the image data, which the network will use to alter the original images to black out any suspected NSFW regions. (Most neural networks don't do mutations that alter their input data.)  Since we're not interested in blacking out anything for our test, we would prefer to ignore this argument, but it has to be supplied, so in the code below we create a `numpy_list` which you can provide as `images=numpy_list`, and then which you can then ignore.\n",
    "\n",
    "**Question 1.4.1**\n",
    "\n",
    "Complete the code below to find any images in the `coco_humans` data set that are flagged by `safety_checker`.\n",
    " * Pass numpy_list and a single 10x3x224x224 pytorch tensor, correctly normalized, each time you call `pipe.safety_checker`.\n",
    " * You might need to make sure the tensor has a device data type that matches the network.\n",
    " * If any of the has_nsfw_concept flags come back `True`, then print the specific image number and display the image.\n",
    "\n",
    "Some hints and sanity checks: It is not a classification dataset, so all the data items have the same class number according to `ImageFolder`.  It should say that 1000 images are available in the data set; and if you examine image number 213 in the data set, you should see a slalom skiier.  A small handful of images will be flagged, including image number 162.  To display a flagged image, you could conver it back to a PIL image, or you could just create a second ImageFolder dataset, one for getting PIL image objects, and one for getting tensors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c7d83",
   "metadata": {
    "id": "d69c7d83"
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "image_dataset = ImageFolder('coco_humans')\n",
    "print(len(image_dataset), 'images available')\n",
    "\n",
    "# CLIP net standard normalization puts numerical image data in a range\n",
    "# with zero mean and unit variance based on empirical data. Source:\n",
    "# https://github.com/openai/CLIP/blob/c5478aac7b9/clip/clip.py#L85\n",
    "clip_transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize([0.48145466, 0.4578275, 0.40821073],\n",
    "              [0.26862954, 0.26130258, 0.27577711]),\n",
    "])\n",
    "\n",
    "# Fix this, but leave the batch_size as 10.\n",
    "for [image_batch, class_numbers] in DataLoader(image_dataset, batch_size=10):\n",
    "    numpy_list = [im.numpy() for im in image_batch]\n",
    "    # TODO: use pipe.safety_checker to flag any images\n",
    "    # and display the image and the index number of each flagged image\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7470738",
   "metadata": {
    "id": "c7470738"
   },
   "source": [
    "**Problem 1.4.2**\n",
    "\n",
    "Fill in the following answers:\n",
    "\n",
    "In the `coco_humans` dataset, the Stable Diffusion safety checker found $\\boxed{\\text{how many?}}$ unsafe images and when looking at them actually $\\boxed{\\text{how many?}}$ were offensive.  When automatic machine-leaned filters are used to omit data, they are typically used with the intention of reducing the chance of propagating offensive or illegal content.  What other potential benefits or drawbacks do you see to using a neural network to filter content?\n",
    "\n",
    "$$\\boxed{\\text{Write a sentence or two of your thoughts below.}}$$\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c959b4",
   "metadata": {
    "id": "e2c959b4"
   },
   "source": [
    "## Backpropagation\n",
    "\n",
    "For part 2 of the homework, proceed to the next notebook."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
